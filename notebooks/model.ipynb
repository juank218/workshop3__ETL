{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../clear_data/happiness_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>year</th>\n",
       "      <th>health</th>\n",
       "      <th>social_support</th>\n",
       "      <th>economy</th>\n",
       "      <th>corruption_perception</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.43630</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country      continent  year   health  social_support  economy  \\\n",
       "0  Switzerland         Europe  2015  0.94143         1.34951  1.39651   \n",
       "1      Iceland         Europe  2015  0.94784         1.40223  1.30232   \n",
       "2      Denmark         Europe  2015  0.87464         1.36058  1.32548   \n",
       "3       Norway         Europe  2015  0.88521         1.33095  1.45900   \n",
       "4       Canada  North America  2015  0.90563         1.32261  1.32629   \n",
       "\n",
       "   corruption_perception  freedom  generosity  happiness_rank  happiness_score  \n",
       "0                0.41978  0.66557     0.29678               1            7.587  \n",
       "1                0.14145  0.62877     0.43630               2            7.561  \n",
       "2                0.48357  0.64938     0.34139               3            7.527  \n",
       "3                0.36503  0.66973     0.34699               4            7.522  \n",
       "4                0.32957  0.63297     0.45811               5            7.427  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 782 entries, 0 to 781\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   country                782 non-null    object \n",
      " 1   continent              782 non-null    object \n",
      " 2   year                   782 non-null    int64  \n",
      " 3   health                 782 non-null    float64\n",
      " 4   social_support         782 non-null    float64\n",
      " 5   economy                782 non-null    float64\n",
      " 6   corruption_perception  782 non-null    float64\n",
      " 7   freedom                782 non-null    float64\n",
      " 8   generosity             782 non-null    float64\n",
      " 9   happiness_rank         782 non-null    int64  \n",
      " 10  happiness_score        782 non-null    float64\n",
      "dtypes: float64(7), int64(2), object(2)\n",
      "memory usage: 67.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting and creating dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_variables(df):\n",
    "    df = pd.get_dummies(df, columns=[\"continent\"])\n",
    "\n",
    "    rename_columns = {\n",
    "        \"continent_North America\": \"continent_North_America\",\n",
    "        \"continent_Central America\": \"continent_Central_America\",\n",
    "        \"continent_South America\": \"continent_South_America\"\n",
    "    }\n",
    "\n",
    "    df = df.rename(columns=rename_columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_dummy_variables(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "To proceed, we divide the data into training and testing sets. Before that, we need to exclude certain columns that won't be useful for our model, which are:\n",
    "\n",
    "happiness_score: This is our target variable, which we want to predict.\n",
    "\n",
    "happiness_rank: This variable is inversely related to our target; including it could create unnecessary complexity and confusion for the model.\n",
    "\n",
    "country: This column contains a large amount of categorical information, which could add extra weight to the training process without offering meaningful insights for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop([\"happiness_score\", \"happiness_rank\", \"country\"], axis=1)\n",
    "target = df[\"happiness_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama単o del conjunto de entrenamiento: (547, 14)\n",
      "Tama単o del conjunto de prueba: (235, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tama単o del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tama単o del conjunto de prueba:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'health', 'social_support', 'economy', 'corruption_perception',\n",
       "       'freedom', 'generosity', 'continent_Africa', 'continent_Asia',\n",
       "       'continent_Central_America', 'continent_Europe',\n",
       "       'continent_North_America', 'continent_Oceania',\n",
       "       'continent_South_America'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'health', 'social_support', 'economy', 'corruption_perception',\n",
       "       'freedom', 'generosity', 'continent_Africa', 'continent_Asia',\n",
       "       'continent_Central_America', 'continent_Europe',\n",
       "       'continent_North_America', 'continent_Oceania',\n",
       "       'continent_South_America'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Model  Mean Squared Error  R2 Score\n",
      "0              Linear Regression            0.210874  0.833289\n",
      "1        Random Forest Regressor            0.171708  0.864253\n",
      "2    Gradient Boosting Regressor            0.171200  0.864654\n",
      "3        Decision Tree Regressor            0.347161  0.725545\n",
      "4  K-Nearest Neighbors Regressor            0.308126  0.756405\n",
      "5       Support Vector Regressor            1.265592 -0.000540\n",
      "6              XGBoost Regressor            0.175235  0.861465\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Random Forest Regressor Model\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=200)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Gradient Boosting Regressor Model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Decision Tree Regressor Model\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "# K-Nearest Neighbors Regressor Model\n",
    "knn_model = KNeighborsRegressor()\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "# Support Vector Regressor Model\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "# XGBoost Regressor Model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Linear Regression\", \"Random Forest Regressor\", \"Gradient Boosting Regressor\",\n",
    "        \"Decision Tree Regressor\", \"K-Nearest Neighbors Regressor\", \"Support Vector Regressor\", \"XGBoost Regressor\"\n",
    "    ],\n",
    "    \"Mean Squared Error\": [mse_lr, mse_rf, mse_gb, mse_dt, mse_knn, mse_svr, mse_xgb],\n",
    "    \"R2 Score\": [r2_lr, r2_rf, r2_gb, r2_dt, r2_knn, r2_svr, r2_xgb]\n",
    "})\n",
    "\n",
    "# Display the results in a table format\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/gb_model.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gb_model, '../model/gb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Training\n",
    "In this section, we assess various regression models to predict happiness scores for countries based on socioeconomic and continental indicators. Each model has unique strengths and methodologies for tackling our prediction task.\n",
    "\n",
    "_Linear Regression_\n",
    "We begin with a linear regression model that assumes a straight-line relationship between the independent features and the target variable.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 0.2109\n",
    "\n",
    "Coefficient of Determination (R族): 0.8333\n",
    "\n",
    "The linear regression model explains approximately 83% of the variance in the happiness scores, suggesting a reasonable fit, though there is potential for improvement with more complex models.\n",
    "\n",
    "_Random Forest Regressor_\n",
    "Next, we apply a Random Forest Regressor, an ensemble technique that aggregates multiple decision trees to produce more reliable and accurate predictions.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 0.1717\n",
    "\n",
    "Coefficient of Determination (R族): 0.8643\n",
    "\n",
    "The Random Forest model achieves a lower MSE and a higher R族 score than linear regression, explaining about 86% of the variance. This suggests it captures more complex, non-linear relationships in the data.\n",
    "\n",
    "_Gradient Boosting Regressor_\n",
    "We then test a Gradient Boosting Regressor, another ensemble model that builds trees sequentially, with each tree aiming to correct errors made by the previous one.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 0.1712\n",
    "\n",
    "Coefficient of Determination (R族): 0.8647\n",
    "\n",
    "The Gradient Boosting model performs comparably to Random Forest, with a marginally lower MSE and similar R族 score, indicating both ensemble methods are effective for this data.\n",
    "\n",
    "_Decision Tree Regressor_\n",
    "We also examine a single Decision Tree Regressor, a simple, interpretable model.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 0.3472\n",
    "\n",
    "Coefficient of Determination (R族): 0.7255\n",
    "\n",
    "The Decision Tree model shows higher error and lower R族 than the ensemble models, as it is more prone to overfitting and lacks the robustness provided by averaging multiple trees.\n",
    "\n",
    "_K-Nearest Neighbors Regressor_\n",
    "The K-Nearest Neighbors (KNN) Regressor predicts based on the average of nearest neighbors in the feature space.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 0.3081\n",
    "\n",
    "Coefficient of Determination (R族): 0.7564\n",
    "\n",
    "The KNN model shows moderate performance, with a higher error than ensemble models. It can be useful for capturing localized patterns but may struggle with global relationships in the data.\n",
    "\n",
    "_Support Vector Regressor_\n",
    "The Support Vector Regressor (SVR) tries to find a hyperplane that best fits the data within a margin of tolerance.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 1.2656\n",
    "\n",
    "Coefficient of Determination (R族): -0.0054\n",
    "\n",
    "The SVR performs poorly here, with a high MSE and a negative R族 score, indicating it does not capture the relationships in this dataset well.\n",
    "\n",
    "_XGBoost Regressor_\n",
    "Finally, we use an XGBoost Regressor, an optimized gradient boosting model known for high performance.\n",
    "\n",
    "Results:\n",
    "Mean Squared Error (MSE): 0.1752\n",
    "\n",
    "Coefficient of Determination (R族): 0.8615\n",
    "\n",
    "The XGBoost model provides competitive results, with performance close to the other ensemble models, capturing non-linear patterns effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
